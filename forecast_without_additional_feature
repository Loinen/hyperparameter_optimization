import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import warnings
import timeit
import seaborn as sns

from sklearn.metrics import mean_absolute_error, mean_squared_error

from fedot.core.data.data import InputData
from fedot.core.pipelines.node import PrimaryNode, SecondaryNode
from fedot.core.pipelines.pipeline import Pipeline
from fedot.core.pipelines.tuning.unified import PipelineTuner
from fedot.core.repository.dataset_types import DataTypesEnum
from fedot.core.repository.tasks import Task, TaskTypesEnum, TsForecastingParams

from main import plot_series, interpolate, comparsion_plot

# Игнорирование возникающих предупреждений.
warnings.filterwarnings('ignore')


def prepare_input_data(len_forecast, train_data_features, train_data_target, test_data_features):
    task = Task(TaskTypesEnum.ts_forecasting, TsForecastingParams(len_forecast))

    train_input = InputData(idx=np.arange(0, len(train_data_features)),
                            features=train_data_features, target=train_data_target,
                            task=task, data_type=DataTypesEnum.ts)

    start_forecast = len(train_data_features)
    end_forecast = start_forecast + len_forecast
    predict_input = InputData(idx=np.arange(0, end_forecast),
                              features=np.concatenate([train_data_features, test_data_features]),
                              target=None, task=task, data_type=DataTypesEnum.ts)

    return train_input, predict_input, task


def run_experiment_with_tuning(time_series, col_name, len_forecast=250, cv_folds=None):
    # Let's divide our data on train and test samples
    train_data = time_series[:-len_forecast]
    test_data = time_series[-len_forecast:]

    # Source time series
    train_input, predict_input, task = prepare_input_data(len_forecast, train_data_features=train_data,
                                                          train_data_target=train_data,
                                                          test_data_features=train_data)
    pipeline = get_complex_pipeline()

    old_predicted, new_predicted = make_forecast_with_tuning(pipeline, train_input, predict_input, task, cv_folds)

    old_predicted = np.ravel(np.array(old_predicted))
    new_predicted = np.ravel(np.array(new_predicted))
    test_data = np.ravel(test_data)

    mse_before = mean_squared_error(test_data, old_predicted, squared=False)
    mae_before = mean_absolute_error(test_data, old_predicted)
    print(f'RMSE before tuning - {mse_before:.4f}')
    print(f'MAE before tuning - {mae_before:.4f}\n')

    mse_after = mean_squared_error(test_data, new_predicted, squared=False)
    mae_after = mean_absolute_error(test_data, new_predicted)
    print(f'RMSE after tuning - {mse_after:.4f}')
    print(f'MAE after tuning - {mae_after:.4f}\n')

    start_point = len(time_series) - len_forecast * 2
    comparsion_plot(pipeline, col_name, ts, old_predicted, new_predicted, len(train_data), start=0)
    comparsion_plot(pipeline, col_name, ts, old_predicted, new_predicted, len(train_data), start_point)


def make_forecast_with_tuning(pipeline, train_input, predict_input, task, cv_folds):
    start_time = timeit.default_timer()
    pipeline.fit_from_scratch(train_input)
    amount_of_seconds = timeit.default_timer() - start_time

    print(f'\nIt takes {amount_of_seconds:.2f} seconds to train pipeline\n')

    # Predict
    predicted_values = pipeline.predict(predict_input)
    old_predicted_values = predicted_values.predict

    pipeline_tuner = PipelineTuner(pipeline, task, iterations=10)
    pipeline = pipeline_tuner.tune_pipeline(input_data=train_input,
                                            loss_function=mean_squared_error,
                                            loss_params={'squared': False},
                                            cv_folds=cv_folds,
                                            validation_blocks=3)

    # Fit pipeline on the entire train data
    pipeline.fit_from_scratch(train_input)
    # Predict
    predicted_values = pipeline.predict(predict_input)
    new_predicted_values = predicted_values.predict

    return old_predicted_values, new_predicted_values


def get_complex_pipeline():
    """
    Pipeline looking like this
    smoothing - lagged - ridge \
                                \
                                 ridge -> final forecast
                                /
                lagged - ridge /
    """

    # First level
    node_smoothing = PrimaryNode('smoothing')

    # Second level
    node_lagged_1 = SecondaryNode('lagged', nodes_from=[node_smoothing])
    node_lagged_2 = PrimaryNode('lagged')

    # Third level
    node_ridge_1 = SecondaryNode('ridge', nodes_from=[node_lagged_1])
    node_ridge_2 = SecondaryNode('ridge', nodes_from=[node_lagged_2])

    # Fourth level - root node
    node_final = SecondaryNode('ridge', nodes_from=[node_ridge_1, node_ridge_2])
    pipeline = Pipeline(node_final)

    return pipeline


if __name__ == "__main__":
    data = pd.read_excel("kaggle/well_log.xlsx", sheet_name=0)
    # убираем лишние столбцы
    data.drop(columns=['SXO', 'Dtsyn', 'Vpsyn', 'sw new', 'sw new%', 'PHI2', 'ΔVp (m/s)'], inplace=True)
    print(data)

    plot_series(data)
    plot_series(data[:100])

    corr = data.corr()  # рисуем корреляционную матрицу
    sns.heatmap(corr, annot=True, fmt='.1f', cmap='Blues')
    plt.show()

    data = interpolate(data)

    for col in list(data.columns):
        ts = np.array(data[col])
        run_experiment_with_tuning(ts, col, len_forecast=500, cv_folds=2)
